<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="RheoAgent: A Cross-Rheological Material Handling Robotic Manipulation System via Hierarchical Decision-Making Framework">
  <meta name="keywords" content="Rheological materials, Rheological heterogeneity, Manipulation, Large Vision-Language Model, Reinforcement learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RheoAgent: A Cross-Rheological Material Handling Robotic Manipulation System via Hierarchical Decision-Making Framework</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

<script>
  document.addEventListener("DOMContentLoaded", () => {
    const images = [
  {
    src: "./static/images/schematic1.jpeg",
    caption: `
      <div class="content has-text-justified">
        <p><strong>a</strong>, The large vision-language model (LVLM) classifies the material as granular or fluid.
        <strong>b</strong>, The robot successfully pours granular material using policy π<sub>A</sub>.
        <strong>c</strong>, A failure case occurs when applying π<sub>A</sub> to a fluid material, resulting in spillage due to viscous fingering.
        <strong>d</strong>, Force-based feedback is used to estimate the fluid's density and viscosity.
        <strong>e</strong>, Policy π<sub>A</sub> is fine-tuned into π<sub>A</sub><sup>&prime;</sup> via parallel training to adapt to the fluid’s rheology.
        <strong>f</strong>, The robot pours the fluid successfully using the adapted policy π<sub>A</sub><sup>&prime;</sup>.</p>
      </div>`
  },
  {
    src: "./static/images/schematic2.jpeg",
    caption: `
      <div class="content has-text-justified">
        <p><strong>g</strong>, RheoAgent demonstrates material-adaptive manipulation across granular materials, inviscid fluids, viscous fluids, and elasto-plastic fluids in a kitchen environment.</p>
      </div>`
  }
];

    let currentIndex = 0;
    const teaserImage = document.getElementById("teaser-image");
    const captionBox = document.getElementById("caption-box");
    const prevBtn = document.getElementById("prev-btn");
    const nextBtn = document.getElementById("next-btn");

    function updateContent(index) {
      teaserImage.src = images[index].src;
      captionBox.innerHTML = images[index].caption;
    }

    prevBtn.addEventListener("click", () => {
      currentIndex = (currentIndex - 1 + images.length) % images.length;
      updateContent(currentIndex);
    });

    nextBtn.addEventListener("click", () => {
      currentIndex = (currentIndex + 1) % images.length;
      updateContent(currentIndex);
    });

    // 初始加载
    updateContent(currentIndex);
  });
</script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- additional js scripts -->
  <script src="./static/js/video-control.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">RheoAgent: A Cross-Rheological Material Handling Robotic Manipulation System via Hierarchical Decision-Making Framework</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com">Haixu Zhang</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Bo Zhang</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Danyang Zhang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Weiqiang Lai</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Xi Chen</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Tin Lun Lam</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Hu Huang</a><sup>1,2</sup>
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Yuan Gao></a><sup>1,2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen</span>
            <span class="author-block"><sup>2</sup>Shenzhen Institute of Artificial Intelligence and Robotics for Society</span>
            <span class="author-block"><sup>3</sup>The College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen</span>
            <span class="author-block"><sup>4</sup>Beijing Institute for General Artificial Intelligence</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948111"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948111"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA111"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies111"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1111"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">

      <!-- ✅ 外层边框容器 + 让其成为相对定位参考点 -->
      <div class="box" style="position: relative; border: 1px solid #ccc; border-radius: 8px; padding: 1rem;">

        <!-- 图片容器（不再负责定位按钮） -->
        <div style="text-align: center;">
          <img id="teaser-image" src="" alt="Schematic image" style="width: 100%; height: auto; border-radius: 8px;">
        </div>

        <!-- 左箭头 -->
        <button id="prev-btn" style="
          position: absolute;
          top: 50%;
          left: -2.5rem;
          transform: translateY(-50%);
          background: white;
          border: 2px solid #ccc;
          border-radius: 50%;
          width: 40px;
          height: 40px;
          cursor: pointer;
          box-shadow: 0 1px 4px rgba(0,0,0,0.1);
        ">
          &#10094;
        </button>

        <!-- 右箭头 -->
        <button id="next-btn" style="
          position: absolute;
          top: 50%;
          right: -2.5rem;
          transform: translateY(-50%);
          background: white;
          border: 2px solid #ccc;
          border-radius: 50%;
          width: 40px;
          height: 40px;
          cursor: pointer;
          box-shadow: 0 1px 4px rgba(0,0,0,0.1);
        ">
          &#10095;
        </button>

        <!-- 图片说明文字 -->
        <div id="caption-box" class="content has-text-justified" style="margin-top: 1rem;">
          <!-- JS 注入 -->
        </div>

      </div> <!-- ✅ box 结束 -->

    </div>
  </div>
</section>



<hr>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robotic manipulation in environments such as biochemical laboratories and kitchens faces challenges due to the rheological heterogeneity of materials, affecting their mechanical response to external forces. Traditional approaches often focus on manipulating materials of a single rheological type, neglecting how operational strategies must adapt when handling materials with varying flow and deformation characteristics. In this work, we introduce a hierarchical decision-making robotic manipulation system for cross-rheological material handling, namely RheoAgent, to tackle the robotics manipulation challenges posed by diverse rheological material scenarios. Our approach combines the material classification capabilities of large vision-language models (LVLMs) — achieving an accuracy of 86.0\% — with dual-modal vision-driven reinforcement learning (RL) using pixel map and voxel map. This integration forms a system capable of flexible operations across various rheological materials. The learning process of the RL module consists of two phases: a rapid learning process for the baseline model and a model fine-tuning process that incorporates specific rheological characteristics, effectively balancing learning costs and model accuracy. Exceeding baseline model-free RL models that have not been fine-tuned by 58.17–98.97\% points through fine-tuning with a model-based approach, the model achieves success rates of 99.08\% and 95.12\% for inviscous materials, 99.07\% and 96.98\% for viscous materials, and 98.53\% and 97.51\% for elasto-plastic materials in the pouring and gathering tasks, respectively. RheoAgent establishes a new paradigm for intelligent material handling, with applications extending to industrial automation, laboratory robotics, and assistive technologies.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="content has-text-justified">
          <p>
            
          </p>
        </div>
      </div>
    </div>
    <!--/ Video. -->
</section>
<hr>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Task Selection Panel -->
    <div class="columns is-vcentered">
      <div class="column is-half">
        <h2 class="title is-3">Fine-tuned Model Evaluation</h2>
      </div>
      
    </div>

    <!-- ✅ 新增说明段落，放在上方整行布局之后 -->
    <div class="columns">
      <div class="column is-full">
        <div class="content">
          <p>
            We evaluated the model in real-world settings by directly deploying the <strong>pre-trained policy</strong>, 
            which was originally trained on <strong>simplified rheological materials</strong> using a 
            <strong>particle-based representation</strong>. This representation captures two fundamental 
            characteristics of rheological materials—<strong>fluidity</strong> and <strong>deformability</strong>. 
            <strong>Fine-tuning further introduced fluid-specific representations</strong> to better capture the 
            <strong>task-relevant dynamics</strong> of particular rheological classes. 
            <strong>The comparison below illustrates the behavioral differences before and after fine-tuning</strong>, 
            showcasing both <strong>successful and failed executions</strong>.
          </p>
        </div>
      </div>
    </div>


    <!-- Task Selection Panel -->
    <div class="columns is-vcentered">
      <div class="column is-half">
        <h3 class="title is-5" style="margin-bottom: 0.5rem;">Comparison between Successful and Failed Executions</h3>
      </div>
    
      <div class="column is-half">
        <div class="columns is-mobile">
          <div class="column">
            <div class="field">
              <label class="label">Task</label>
              <div class="control">
                <div class="select is-fullwidth">
                  <select id="task-select">
                    <option>Pour task</option>
                    <option>Gather task</option>
                  </select>
                </div>
              </div>
            </div>
          </div>
    
          <div class="column">
            <div class="field">
              <label class="label">Material</label>
              <div class="control">
                <div class="select is-fullwidth">
                  <select id="material-select">
                    <option>Inviscid fluid</option>
                    <option>Viscous fluid</option>
                    <option>Elasto-plastic fluid</option>
                  </select>
                </div>
              </div>
            </div>
          </div>
        </div>
        
      </div>
      
    </div>

    <!-- Success or Fail Video Display -->
    <div class="columns">
      <div class="column has-text-centered">
        <p class="subtitle is-5">Success</p>
        <video id="video-success" controls muted autoplay playsinline width="100%" style="background-color: #000;">
          <source id="source-success" src="" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p id="fallback-success" style="color: red; display: none;">No success video for this combination.</p>
    
        <!-- ✅ 成功视频的 caption 放在这里 -->
        <p id="caption-success" class="content is-small" style="margin-top: 0.5rem; text-align: left;"></p>
      </div>
    
      <div class="column has-text-centered">
        <p class="subtitle is-5">Fail</p>
        <video id="video-fail" controls muted autoplay playsinline width="100%" style="background-color: #000;">
          <source id="source-fail" src="" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p id="fallback-fail" style="color: red; display: none;">No fail video for this combination.</p>
    
        <!-- ✅ 失败视频的 caption 放在这里 -->
        <p id="caption-fail" class="content is-small" style="margin-top: 0.5rem; text-align: left;"></p>
      </div>
    </div>

    <!-- gif -->
    <!-- <div class="content">
      <h3 class="title is-8">Pour Task – Elasto-plastic Fluid</h3>
    </div> -->
    <div class="gif-group-box">
      <div class="gif-group-header">
        <p class="gif-group-title">Pour Task – Elasto-plastic Fluid</p>
      </div>
      <div class="gif-grid">
        <img src="./static/videos/GIF/6865-1.gif" alt="gif">
        <img src="./static/videos/GIF/6869-1.gif" alt="gif">
        <img src="./static/videos/GIF/6873-1.gif" alt="gif">
        <img src="./static/videos/GIF/6876-1.gif" alt="gif">
        <img src="./static/videos/GIF/6879-1.gif" alt="gif">
        <img src="./static/videos/GIF/6886-1.gif" alt="gif">
        <img src="./static/videos/GIF/6892-1.gif" alt="gif">
        <img src="./static/videos/GIF/6895-1.gif" alt="gif">
        <img src="./static/videos/GIF/6898-1.gif" alt="gif">
        <img src="./static/videos/GIF/6901-1.gif" alt="gif">
        <img src="./static/videos/GIF/6919-1.gif" alt="gif">
        <img src="./static/videos/GIF/6933-1.gif" alt="gif">

        <img src="./static/videos/GIF/6942-1.gif" alt="gif">
        <img src="./static/videos/GIF/6947-1.gif" alt="gif">
        <img src="./static/videos/GIF/6952-1.gif" alt="gif">
        <img src="./static/videos/GIF/6942-1.gif" alt="gif">
        <img src="./static/videos/GIF/6955-1.gif" alt="gif">
        <img src="./static/videos/GIF/6958-1.gif" alt="gif">
        <img src="./static/videos/GIF/6963-1.gif" alt="gif">
        <img src="./static/videos/GIF/6979-1.gif" alt="gif">
        <img src="./static/videos/GIF/6985-1.gif" alt="gif">
        <img src="./static/videos/GIF/6989-1.gif" alt="gif">
        <img src="./static/videos/GIF/7002-1.gif" alt="gif">
        <img src="./static/videos/GIF/7007-1.gif" alt="gif">
      </div>
  </div>

  <hr>

    <!-- 外部包裹容器，添加边框和圆角 -->
    <div class="box" style="border: 1px solid #ccc; border-radius: 8px; padding: 1rem;">

      <!-- 图片本身 -->
      <img id="teaser" src="./static/images/real_exp2.png" alt="Schematic image" style="width: 100%; height: auto;">

      <!-- caption 内容 -->
      <div class="content has-text-justified" style="margin-top: 1rem;">
        <p>
          <strong>Real-world performance of the pre-trained model (trained on granular materials).</strong>
          <strong>a</strong>, Real-world performance of the pre-trained model (trained on granular materials).
          <strong>b</strong>, Sequential frames illustrating a real-world gathering scenario.
        </p>
      </div>

    </div>

    <!-- Segmentation. -->
    <!-- <hr style="border: none; border-top: 1px solid #ccc; margin: 1rem 0;"> -->
    <hr>
    <h3 class="title is-3">Real-time Segmentation and Perception Mapping</h2>

    <img id="teaser" src="./static/images/real_visual.png" alt="Schematic image" style="width: 100%; height: auto;">
    <div class="content has-text-justified">
      <p>
        <strong>Visual encoding pipeline for real-world rheological perception.</strong>
        <strong>a</strong>, Schematic of the real-world perception system. A dual-camera configuration mitigates point cloud occlusion. Green and blue arrows denote the viewing directions for generating voxel and pixel maps, respectively.
        <strong>b</strong>, <a href="https://ai.meta.com/sam2/" target="_blank">SAM2</a>-based segmentation of kinetic sand from dual perspectives.
        <strong>c</strong>, Agent-centric viewer constructed from multi-view fused point clouds. The blue spherical region denotes the field of view, where yellow and purple indicate closer and farther regions.
        <strong>d</strong>, Top-down view of the fused point cloud, used for constructing orthographic projections.
        <strong>e</strong>, Equirectangular projection of the spherical view forming the voxel map, based on latitude–longitude grid discretization with per-cell nearest distance encoding.
        <strong>f</strong>, Rasterized orthographic pixel map derived from the top-down projection of the segmented point cloud.
      </p>
    </div>
  
    <div class="content has-text-justified">
      <p>
        We employ the <strong>Segment Anything Model 2 (SAM2)</strong> to perform real-time segmentation of rheological materials from RGB-D inputs.
        To build a consistent spatial understanding, <strong>multi-view RGB-D frames</strong> are fused into a globally aligned segmented point cloud.
        This point cloud is then encoded into two representations:
      </p>
      <ul>
        <li><strong>Pixel map</strong>: generated via orthographic projection of the segmented point cloud onto the vertical plane.</li>
        <li><strong>Voxel map</strong>: constructed by encoding spatial occupancy on a latitude-longitude grid with normalized distances.</li>
      </ul>
      <p>
        These representations serve as structured perceptual inputs for downstream robotic manipulation policies.
      </p>
    </div>
    <div class="content has-text-centered">
      <video id="replay-video"
              controls
              muted
              preload
              playsinline
              width="100%">
        <source src="./static/videos/perception.mp4"
                type="video/mp4">
      </video>
    </div>
    <!--/ Segmentation. -->
    <div class="columns is-centered">

      <!-- Pour. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Pouring Under Human Disturbance</h2>
          <p>
            The robot continues pouring while a human introduces interference by shifting the target cup.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/external_pour.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Pour. -->

      <!-- Gather. -->
      <div class="column">
        <h2 class="title is-3">Gathering Under Human Disturbance</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              The robot continues collecting while a human introduces interference by adding material during and after the task.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/external_gather.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Gather. -->

    <!-- Re-rendering. -->
    <h3 class="title is-3">Multi-Robot Collaboration: Collection</h2>
      <div class="content has-text-justified">
        <p>
          Two robots cooperate in a gathering task: the dual-arm Elephant Mercury B1 pushes material with a plate, while the UR5 collects it using a cup.
        </p>
      </div>
      <div class="content has-text-centered">
        <video id="replay-video"
                controls
                muted
                preload
                playsinline
                width="100%">
          <source src="./static/videos/multi-agent.mp4"
                  type="video/mp4">
        </video>
      </div>
      <!--/ Re-rendering. -->
    
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          <!-- <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{haixu2025nmi,
  author    = {Haixu Zhang, Bo Zhang, Danyang Zhang, Xi Chen, Wenqiang Lai, Chi Zhang, Tin Lun Lam, Hu Huang, Yuan Gao},
  title     = {RheoAgent: A Cross-Rheological Material Handling Robotic Manipulation System via Hierarchical Decision-Making Framework},
  journal   = {xxx},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<hr>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Related work. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Related work</h2>
        <img id="teaser" src="./static/images/related_work_real_finial.png" alt="Schematic image" style="width: 100%; height: auto;">
        <div class="content has-text-centered">
          <p>
            Overview of robotic system manipulation of rheological materials.
          </p>
        </div>
      </div>
    </div>
    <!--/ Related work. -->

    <!-- Method. -->
    <div class="columns is-centered has-text-justified">
      <div class="column is-four-fifths">
        <h2 class="title is-3">How does it work?</h2>
        <img id="teaser" src="./static/images/method_nmi.png" alt="Schematic image" style="width: 100%; height: auto;">
        <div class="content has-text-centered">
          <p>
            Overview of robotic system manipulation of rheological materials.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
</section>

</body>
</html>
